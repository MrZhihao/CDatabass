---
layout: page
---

# A1: Operator Logic

* Released: 9/10
* Due: 9/20 11:59PM EST
* Teams of 1 or 2

You only need to submit 1 repo. Please add the staff GitHub ID (deka108, sirrice) as collaborators to the repo and your teammate's GitHub ID if you're working with a team of 2.

In this assignment, you will implement the iterator model for the DataBass query execution engine.  This will get you familiarized with how a class row-oriented engine might run.    Once A0's submission deadline has passed, we will update the `databass-public` repo with A0 solutions. You can then rebase the solution from `databass-public` to your work branch using

```bash
git fetch upstream
git rebase upstream/master
```

You will need to implement two main things: how to infer and initialize the output schema for a subset of the operators, and the `__iter__()` method for most operators.  We have provided default implementations for all operators other than those you will implement.

The primary files to modify are in [databass/ops](../databass/ops)

We have provided implementations of the following operators:

* Scan
* Filter
* ThetaJoin (aka nested loops join)

You will implement the following operators: 

* SubQuerySource
* Hashjoin
* GroupBy
* Limit
* Distinct

## init_schema

The purpose of `init_schema` is to infer the output schema for an operator, given the schema of its child operators.  After a query plan is constructed, DataBass performs a bottom-up traversal of the plan (starting from leaf operators) and calls `init_schema`.   You can see this in `optimizer.py:initialize_plan`.   We have implemented `init_schema` for Scan, Filter, and in the base operators (baseops.py).

The reason why initializing the schemas is important is because each Attr reference in an operator's expressions (say in a project clause or predicate) needs to know  how to index into a tuple's list of values in order to retreive the appropriate value.   Rather than doing this dynamically, we want to figure out the index during query parsing/initialization so that later lookups are faster.  You will see how the code in `optimizer.py:disambiguate_op_attrs()` goes through each Attr reference and tries to disambiguate it and figure out the index value (stored in Attr.idx).

This is particularly useful for optimization and compilation.

## iterator

Each `__iter__` method is a [Python generator](https://wiki.python.org/moin/Generators) that is implemented by calling `yield` on each output row.  This lets you loop through an operator, which you can see in our implementation of Filter and ThetaJoin.  

Typically, query engines try to avoid allocating new memory for every intermediate row by pre-allocating a "tuple slot" whose pointer is simply passed around.  Thus each operator's job is to populate the contents of this single slot that the parent operator will read.  Even though DataBass is implemented in Python, we still implement a similar strategy.


## Tasks

We have split HW1 into three phases, from simpler operators to more challenging operators.   

#### Phase 1:

You will implement

* `Distinct.__iter__()`
* `Limit.__iter__()`

Test your code by running:

        pytest test/a1.py -k "test_phase1"


### Phase 2:

Finally, you will implement:

* `SubQuerySource.__iter__()` 
* `HashJoin.__iter__()`, `HashJoin.build_hash_index()`
* `GroupBy.__iter__()`

Test your code by running:

        pytest test/a1.py -k "test_phase2"

## Submission

1. Use 1 repo for submission. Make sure your solution has been pushed to the appropriate branch, which is `a1` in this case.
2. Make sure the staff (deka108, sirrice) and your teammate (if any) GitHub ID have been added as collaborators to the repo
3. Fill out [this google form](https://forms.gle/G4rHEjnC3UZzjKht8)
