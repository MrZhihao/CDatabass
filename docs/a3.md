---
layout: page
---


## A3: Query Compilation 

* Released:  10/1
* Due: 10/21 11:59PM EST
* Teams of 1 or 2

Finally!   You will implement query compilation for some basic relational operators, by using the produce-consume model described in the Neumann paper.
To make your life easier, we have included compilation implementations for all operators not related to this assignment.

Details about how compilation works can be found in the [module's README](../databass/compile/README.md).  Please read it before proceeding.  

This is certainly the most challenging assignment, and you'll need to dig through some of the codebase,  so get started early.  You're encouraged to discuss with your classmates (but not share code or solutions).   We are happy to walk through the code in office hours!  

You will implement compilation for:

* Expr objects
* Hash join 
* Group By 

We recommend implementing them in that order, since the difficulty gets progressively harder.


## The Assignment

### Implementing Compilation

#### Task 1: Expression Compilation


You will edit code in [PyTranslator](../databass/compile/py/translator.py) to compile `Expr` objects into raw Python.  You will implement two versions, the first turns the Expr object into multiple lines and assigns the result to a new variable.  The second turns the Expr object into an inline-able string---this is possible if the expression does not refer to any aggregation functions (which require multiple lines to setup).

Test your code by running:

        $ pytest test/a3.py -k "test_expr"


#### Task 2: HashJoin

Implement the HashJoin operator in [`hashjoin.py`](../databass/compile/py/hashjoin.py).  The tricky part is that join is a binary operator.  Logically, you will want the control flow to flow down to the left child, which will flow back up to the join, and then flow down to the right child, and then back up to the join.  

                        join
                      / /  \ \
                     ↓ ↑    ↓ ↑ 
                    left    right

To do so, we model hash join as separate left and right translators.  Since the left side is a pipeline breaker,
we end up with two pipelines:

    pipeline 1: [ ..., left, leftTranslator]
    pipeline 2: [ ..., right, rightTranslator]


The leftTranslator's produce will be called first, and populate the Join's hash table.  Once the pipeline
is complete, the pipeline 2's produce will be called, and the right Translator will iterate over 
the tuples in `right` and probe the hash table.    

Test your code by running:

        $ pytest test/a3.py -k "test_hashjoin"


#### Task 3: Aggregation 

Please implement compilation for the GroupBy operator in [`agg.py`](../databass/compile/py/agg.py).

Test your code by running:

        $ pytest test/a3.py -k "test_groupby"


## Submission

1. Make sure your solution has been pushed to the appropriate branch
2. Make sure the staff have been added as collaborators to the repo
3. Fill out [this google form](https://forms.gle/2dDfME1Vj3P55raM7)

