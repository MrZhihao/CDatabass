---
layout: page
---


## A2: Query Optimization

* Released: 9/17
* Due: 10/4 11:59PM EST
* Teams of 1 or 2


You will now implement Selinger join optimization in DataBass!  To do so, you will implement the dynamic programming optimization algorithm, as well as some basic cardinality and selectivity estimation.

Please read the [optimizer design doc](../databass/optimizer/README.md).  You will primarily modify code in [`databass/optimizer`](../databass/optimizer).

## The Assignment

Please note that the assignment is fairly open ended. Other than generating correct physical plans, and coming within 20% of the reference implementation, anything goes.  The comments in the code are to help guide you towards a reasonable implementation, but the sky is the limit.

If you encounter bugs, either [submit an issue](https://github.com/w6113/databass-public/issues/new) or let us know on slack.  Providing a simple test input/case and location in the code helps immensely.  

#### Task 1: Cost Estimation

Please edit [`estimation.py`](../databass/optimizer/estimation.py) to implement selectivity estimation for attributes, predicates, and join operators.
Going beyon the assignment, you could implement column/multi-column histograms for more accurate estimates -- you should expect to see an effect on datasets that contain skew or "hot keys".


#### Task 2: Selinger Optimization

Please edit [`selinger.py`](../databass/optimizer/selinger.py) to implement the join optimization logic.
We have included sample code in [`test.py`](../test.py) that runs and compares the two optimizers on randomly generate join plans.  Feel free to use it to aid debugging.

#### Evaluation

Since join optimization cannot be evaluated via a correct/incorrect judgement, we will evaluate your submissions via two criteria:

* Efficiency of selinger algorithm: the number of plans that are costed during Selinger optimization.   We expect it to be lower than the exhaustive algorithm, and within 10\% of our implementation of Selinger.  The test cases include our numbers as a sanity check.
* The wallclock time of your optimized plan, when run on our machines, should be within 10% of the plan that our implementation generates.

It is absolutely possible to do better than the reference implementation, since it uses naive statistics.

The tests can be run using:

      $ pytest test/a2.py 


## Submission

1. Make sure your solution has been pushed to the appropriate branch
2. Make sure the staff have been added as collaborators to the repo
3. Fill out [this google form](https://forms.gle/xcMVdJ6NfDMkXh5k7)

